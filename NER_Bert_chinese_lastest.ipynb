{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTmNj95EJub3"
   },
   "source": [
    "# Named Entity Recognition with BERT in PyTorch\n",
    "Based: https://towardsdatascience.com/named-entity-recognition-with-bert-in-pytorch-a454405e0b6a  \n",
    "library: Hugging face's \"Transformer\"   \n",
    "Êï∞ÊçÆÂ∫ìÂ≠òÂú®ËÑèÊï∞ÊçÆÔºÅlabelÂíåËØçÈïøÂ∫¶‰∏ç‰∏ÄËá¥  \n",
    "We use \"BertFortokenClassification\" instead of \"BertForSequenceClassification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f_akTVv8EAkx"
   },
   "outputs": [],
   "source": [
    "# Mode chosing\n",
    "Colab=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r3Ycr6F5J76T",
    "outputId": "9df99e1c-b59b-413c-c5da-4fec492f664d"
   },
   "outputs": [],
   "source": [
    "#######For google\n",
    "if Colab:\n",
    "    !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uTa_0utiJub8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizerFast\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertForTokenClassification\n",
    "from torch.utils.data import DataLoader    \n",
    "#if we use import torch.utils.data.DataLoader as Dataloader, here dataloader is a module\n",
    "#but here, from torch,utils.data import dataloader is now a function\n",
    "import torch.optim as optim   #Here optim is still a module, we always use optim.SGD to create a function SGD\n",
    "from tqdm import tqdm   #same reason, if we \"import tqdm\" directly, will be error: module is not callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_XQJrOzKfgp",
    "outputId": "c227ba49-906e-4eb9-cdcc-7971390c8cac"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './People_dalily_10000_examples_adapted.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c06391aae8f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m####load(local)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./People_dalily_10000_examples_adapted.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 )\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1727\u001b[0m                 \u001b[0mis_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1728\u001b[0m                 \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1729\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1730\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    858\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './People_dalily_10000_examples_adapted.csv'"
     ]
    }
   ],
   "source": [
    "########Load from gdrive\n",
    "if Colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Input/People_dalily_10000_examples_adapted.csv\")\n",
    "\n",
    "\n",
    "####load(local) \n",
    "else:\n",
    "    df=pd.read_csv('./People_dalily_10000_examples_adapted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "9slZGLglJub-",
    "outputId": "f433d064-ad42-4d69-e9ab-08dfa8de0d1c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‰∫∫ Ê∞ë ÁΩë 1 Êúà 1 Êó• ËÆØ ÊçÆ „Ää Á∫Ω Á∫¶ Êó∂ Êä• „Äã Êä• ÈÅì , Áæé ÂõΩ Âçé Â∞î Ë°ó ...</td>\n",
       "      <td>O O O B_T I_T I_T I_T O O O B_LOC I_LOC O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>„Ää Á∫Ω Á∫¶ Êó∂ Êä• „Äã Êä• ÈÅì ËØ¥ , Ê†á ÊôÆ 5 0 0 Êåá Êï∞ ‰ªä Âπ¥ ‰∏ä Âçá 2 9 ...</td>\n",
       "      <td>O B_LOC I_LOC O O O O O O O O O O O O O O B_T ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Â∞± 1 2 Êúà 3 1 Êó• Êù• ËØ¥ , Áî± ‰∫é Â∞± ‰∏ö Ââç ÊôØ Áúã Â•Ω Âíå Áªè Êµé Â¢û Èïø ...</td>\n",
       "      <td>O B_T I_T I_T I_T I_T I_T O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Âè¶ ÊçÆ „Ää Âçé Â∞î Ë°ó Êó• Êä• „Äã Êä• ÈÅì , 2 0 1 3 Âπ¥ ÊòØ 1 9 9 5 Âπ¥ ...</td>\n",
       "      <td>O O O B_LOC I_LOC I_LOC O O O O O O B_T I_T I_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‰∫∫ Ê∞ë ÁΩë Âπ≥ Â£§ 1 Êúà 1 Êó• Áîµ ( ËÆ∞ ËÄÖ Áéã Ëéâ „ÄÅ Á®ã Áª¥ ‰∏π ) Êúù È≤ú ÊúÄ ...</td>\n",
       "      <td>O O O B_LOC I_LOC I_T I_T I_T I_T O O O O B_PE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  ‰∫∫ Ê∞ë ÁΩë 1 Êúà 1 Êó• ËÆØ ÊçÆ „Ää Á∫Ω Á∫¶ Êó∂ Êä• „Äã Êä• ÈÅì , Áæé ÂõΩ Âçé Â∞î Ë°ó ...   \n",
       "1  „Ää Á∫Ω Á∫¶ Êó∂ Êä• „Äã Êä• ÈÅì ËØ¥ , Ê†á ÊôÆ 5 0 0 Êåá Êï∞ ‰ªä Âπ¥ ‰∏ä Âçá 2 9 ...   \n",
       "2  Â∞± 1 2 Êúà 3 1 Êó• Êù• ËØ¥ , Áî± ‰∫é Â∞± ‰∏ö Ââç ÊôØ Áúã Â•Ω Âíå Áªè Êµé Â¢û Èïø ...   \n",
       "3  Âè¶ ÊçÆ „Ää Âçé Â∞î Ë°ó Êó• Êä• „Äã Êä• ÈÅì , 2 0 1 3 Âπ¥ ÊòØ 1 9 9 5 Âπ¥ ...   \n",
       "4  ‰∫∫ Ê∞ë ÁΩë Âπ≥ Â£§ 1 Êúà 1 Êó• Áîµ ( ËÆ∞ ËÄÖ Áéã Ëéâ „ÄÅ Á®ã Áª¥ ‰∏π ) Êúù È≤ú ÊúÄ ...   \n",
       "\n",
       "                                              labels  \n",
       "0  O O O B_T I_T I_T I_T O O O B_LOC I_LOC O O O ...  \n",
       "1  O B_LOC I_LOC O O O O O O O O O O O O O O B_T ...  \n",
       "2  O B_T I_T I_T I_T I_T I_T O O O O O O O O O O ...  \n",
       "3  O O O B_LOC I_LOC I_LOC O O O O O O B_T I_T I_...  \n",
       "4  O O O B_LOC I_LOC I_T I_T I_T I_T O O O O B_PE...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df=pd.read_csv('ner.csv')   #Not completed, like \"Demonstrators\" not regard as ent\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrGeBoY6JucA"
   },
   "source": [
    "## Give ids to labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bK_pZSJmJucB",
    "outputId": "c9ac5345-bac3-4bfa-c483-ffc680d9e619"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'B_LOC', 1: 'B_ORG', 2: 'B_PER', 3: 'B_T', 4: 'I_LOC', 5: 'I_ORG', 6: 'I_PER', 7: 'I_T', 8: 'O'}\n"
     ]
    }
   ],
   "source": [
    "# Split labels based on whitespace and turn them into a list\n",
    "labels = [i.split() for i in df['labels'].values.tolist()]\n",
    "\n",
    "# Check how many labels are there in the dataset\n",
    "unique_labels = set()\n",
    "\n",
    "for lb in labels:\n",
    "  [unique_labels.add(i) for i in lb if i not in unique_labels]   #here .add is fun without return value, thus if we set a=[...], \n",
    "                                                                  # a will =[]\n",
    "\n",
    "# Map each label into its id representation and vice versa\n",
    "labels_to_ids = {k: v for v, k in enumerate(sorted(unique_labels))}\n",
    "ids_to_labels = {v: k for v, k in enumerate(sorted(unique_labels))}\n",
    "print(ids_to_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rf0A1ZezJucC"
   },
   "source": [
    "## Tokenize(Output directly become tensor)\n",
    "Bert tokenizer can transform a sentence in nl to a list of number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "f816a3771dca4f4ba559ac3ad41213bb",
      "a0d88595282e4d3c9cbb558f39826fa1",
      "2fd2ca56be0c40c89a18406f4ddfcee0",
      "1895bcecaad248f1a3629ca628c0113d",
      "e146fc0fdad84efbbb060632723d391c",
      "bf106b03f01f43378a87170bf130cb9b",
      "349e61635cc74c3880e1dcdc424fbefa",
      "f00e2a50058944478fda51f7fd5cfe5b",
      "cd468a3294e94e248920887ec1fd1247",
      "f80873f4dc5245f1acbd5dcd06e682d2",
      "5e94c4476ad04f4680e1a76eaa563cca",
      "554e0596bc924337beb2e7903f1932f4",
      "d5eab144ca1346fd89d614753ad8fad0",
      "f2e1dec4abfe4076b32567bdd67ec738",
      "18619a87d26f44769572d9b86fe27b2f",
      "3e9c6c4b3f5849069716235ad5a59a6c",
      "927a24da570342b093add93c64406361",
      "f84a480e089d4364bc9c2860a5e76269",
      "39b2ec0232cc4c8d9f94edbd6f6f5824",
      "21a253b6aba54884bc6c461e2aca5638",
      "b1b34f2edb3a4b1db14f0771065d7142",
      "1a59fe7300b2425e8f8022516e2596ff",
      "c093c6bfe8ab4b69afdb8e63a7a72819",
      "f3f82e10e0ea4231b254d68d190325f4",
      "2f738a04f2b64ad3b3769c5e2bfa6947",
      "844fe36ff8b44ff197623646fede713f",
      "f0c00fa682254c1fbcb0f9db06b8d5b2",
      "fb8a3663a8cc40d288ecc0352baae919",
      "b3c99eb84abb410d9888f87631803b22",
      "ec495c84fa9a45e5ac826c004d41ef81",
      "0b30e1f9dd8145dc896b42cf5f6e75db",
      "c614b67cadb9465492de63927172911f",
      "b8a66518d8dc4853a607a968e51d2cea",
      "f3c4a4db469d436c9ef388d018c8fd33",
      "2f85a6c8c3e94cc2ac9a7ceb2117c84e",
      "26440bb6e9ec49949fb645db9ef4ea97",
      "2e8f932a01244043924c9270c7723e88",
      "f048a8857a654458af82e4f53ada6ce5",
      "dd8efd9f3b844144b3d20bacb0ce1cee",
      "f6201b0f0b00482bb50c6034380e1f98",
      "62fa584e4b8f4699bea1479002ff9f81",
      "701f66158a644085a7648fd5279006d2",
      "b19e14b78e844adc9068ea51cef7faf9",
      "1d6de102451b4d95962167f504afcd08"
     ]
    },
    "id": "51TrjL5aJucC",
    "outputId": "8d54d543-1189-476b-e376-2c8b73e36c82"
   },
   "outputs": [],
   "source": [
    "# Let's take a look at how can we preprocess the text - Take first example\n",
    "text = df['text'].values.tolist()\n",
    "example = text[36]   #get one sentence (THE 36th sentence)\n",
    "\n",
    "#tokenize by bert\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-chinese')\n",
    "text_tokenized = tokenizer(example, padding='max_length', max_length=512, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "#3 layer can be found: input_ids, token_type_ids,atention_mask\n",
    "#print(text_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7L9Vz6v7JucD"
   },
   "source": [
    "### decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TXFVfD1rJucE"
   },
   "outputs": [],
   "source": [
    "#print(tokenizer.decode(text_tokenized.input_ids[0][0:50]))    #0 is the first sentence,since here we have only one sentence to tokenize\n",
    "#we can't decode more than 1 sentence with .decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcNmzzKiJucF"
   },
   "source": [
    "### \"Convert ids to token\" will find Bert's\"subword\" problem\n",
    "The BERT tokenizer uses the so-called word-piece tokenizer under the hood, which is a sub-word tokenizer. This means that BERT tokenizer will likely to **split one word into one or more meaningful sub-words**.\n",
    "*Which make label provided by database can't match tokens*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oe5YyieKJucH",
    "outputId": "30be1e7b-ed79-4c73-a0ae-0815282247c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'Êñ∞', 'Âπ¥', 'Ââç', 'Â§ï', ',', 'ÂõΩ', 'ÂÆ∂', '‰∏ª', 'Â∏≠', '‰π†', 'Ëøë', 'Âπ≥', 'ÈÄö', 'Ëøá', '‰∏≠', 'ÂõΩ', 'ÂõΩ', 'ÈôÖ', 'Âπø', 'Êí≠', 'Áîµ', 'Âè∞', '„ÄÅ', '‰∏≠', 'Â§Æ', '‰∫∫', 'Ê∞ë', 'Âπø', 'Êí≠', 'Áîµ', 'Âè∞', '„ÄÅ', '‰∏≠', 'Â§Æ', 'Áîµ', 'ËßÜ', 'Âè∞', ',', 'Âèë', 'Ë°®', '‰∫Ü', '2', '0', '1', '4', 'Âπ¥', 'Êñ∞', 'Âπ¥', 'Ë¥∫']\n",
      "[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48]\n"
     ]
    }
   ],
   "source": [
    "######Check output of word_ids, we will find it pretty smart:\n",
    "######First token [CLS] is marked as None, which avoid the movement of whole sentence\n",
    "######All words are marked with their real \"index\" in \"labels list\"(0st word is Prime, and 3rd word is G+ei+r)\n",
    "word_ids = text_tokenized.word_ids()\n",
    "print(tokenizer.convert_ids_to_tokens(text_tokenized[\"input_ids\"][0])[0:50])\n",
    "print(word_ids[0:50])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQ1avpX_JucH"
   },
   "source": [
    "### Two method can be applied to solve this problem:\n",
    "These word_ids will be very useful to adjust the length of the label by applying either of these two methods:  \n",
    "\n",
    "1, We only provide a label to the first sub-word of each splitted token. The continuation of the sub-word then will simply have ‚Äò-100‚Äô as a label. All tokens that don‚Äôt have word_ids will also be labeled with ‚Äò-100‚Äô.  \n",
    "2, We provide the same label among all of the sub-words that belong to the same token. All tokens that don‚Äôt have word_ids will be labeled with ‚Äò-100‚Äô."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hlsdh7_cJucI"
   },
   "outputs": [],
   "source": [
    "def align_label_example(tokenized_input, labels,labels_to_ids,label_all_tokens):\n",
    "    '''\n",
    "    output: labels_ids\n",
    "    \n",
    "    '''\n",
    "    word_ids = tokenized_input.word_ids()\n",
    "\n",
    "    previous_word_idx = None\n",
    "    label_ids = []\n",
    "    #print('word')\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            label_ids.append(-100)\n",
    "            \n",
    "        elif word_idx != previous_word_idx:\n",
    "            try:\n",
    "                label_ids.append(labels_to_ids[labels[word_idx]])  #As we mention, word_idx is exactly \n",
    "            except:\n",
    "                label_ids.append(-100)   #Ê≠§Â§ÑÊòØÈÅøÂÖçËÑèÊï∞ÊçÆÁöÑÂΩ±ÂìçÔºàÂç≥labelÁöÑÈïøÂ∫¶ÂíåÂÆûÈôÖÁöÑÂè•Â≠êÈïøÂ∫¶‰∏çÂêåÔºâ\n",
    "    \n",
    "        else:\n",
    "            # print('label_id', label_ids)\n",
    "            # print('word_ids ',word_ids[0:50])\n",
    "            # #print('label[word]', labels[word_idx])\n",
    "            # print('label list ', len(labels))\n",
    "            try:\n",
    "                label_ids.append(labels_to_ids[labels[word_idx]] if label_all_tokens else -100)\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "\n",
    "\n",
    "        previous_word_idx = word_idx\n",
    "    \n",
    "\n",
    "    return label_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-fUGFacJucJ"
   },
   "source": [
    "## New lables for bert to train\n",
    "Since original labels can't match with its token list, we create a new lables list to fit it  \n",
    "what is more, we present labels in ids form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ryHR4S01JucJ",
    "outputId": "b609d770-5734-4ae8-c58f-f8fc80324e40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 3, 7, 8, 8, 8, 8, 8, 8, 8, 2, 6, 6, 8, 8, 0, 4, 8, 8, 8, 8, 8, 8, 8, 8]\n",
      "['[CLS]', 'Êñ∞', 'Âπ¥', 'Ââç', 'Â§ï', ',', 'ÂõΩ', 'ÂÆ∂', '‰∏ª', 'Â∏≠', '‰π†', 'Ëøë', 'Âπ≥', 'ÈÄö', 'Ëøá', '‰∏≠', 'ÂõΩ', 'ÂõΩ', 'ÈôÖ', 'Âπø', 'Êí≠', 'Áîµ', 'Âè∞', '„ÄÅ', '‰∏≠']\n"
     ]
    }
   ],
   "source": [
    "label = labels[36]\n",
    "\n",
    "#If we set label_all_tokens to True.....\n",
    "label_all_tokens = True\n",
    "\n",
    "new_label = align_label_example(text_tokenized, label,labels_to_ids,label_all_tokens)\n",
    "print(new_label[0:25])   #he\n",
    "print(tokenizer.convert_ids_to_tokens(text_tokenized[\"input_ids\"][0])[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZxEVx6GJucK"
   },
   "source": [
    "## Dataset Class(tokenize include)\n",
    "Before we train our BERT model for NER task, we need to create a dataset class to generate and fetch data in a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Yj3AkvkmJucK"
   },
   "outputs": [],
   "source": [
    "##### NOt a simple class of dataset, we also realise tokenizer here\n",
    "\n",
    "class DataSequence(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df,labels_to_ids,label_all_tokens):\n",
    "\n",
    "        lb = [i.split() for i in df['labels'].values.tolist()]\n",
    "        txt = df['text'].values.tolist()   #list of sentence\n",
    "        \n",
    "        text_tokenized = [tokenizer(str(i),\n",
    "                               padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\") for i in txt] \n",
    "        \n",
    "        self.texts=text_tokenized\n",
    "         \n",
    "        self.labels = [align_label_example(i,j,labels_to_ids,label_all_tokens) for i,j in zip(text_tokenized, lb)]\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_data(self, idx):\n",
    "\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "\n",
    "        return torch.LongTensor(self.labels[idx])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_data = self.get_batch_data(idx)\n",
    "        batch_labels = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_data, batch_labels   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ie32NrQLJucL"
   },
   "source": [
    "### Train val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Jl9k250hJucL"
   },
   "outputs": [],
   "source": [
    "df = df[0:1000]    #we pick only 1000 example\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42),    \n",
    "                            [int(.8 * len(df)), int(.9 * len(df))])    #split the lisy into 3 parts, with 2 cut\n",
    "                                                                        #one cut at 0.8*len(df)\n",
    "                                                                        #one cut at 0.9*len(df)\n",
    "                                                                        #so train:val:test=8:1:1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdalS2vCJucL"
   },
   "source": [
    "#### Test Datasequence (check with class \"Datasequence\"'s return)\n",
    "Find that output of DataSequence is a list with len of nb_sentence,  and each elements is a tuple  \n",
    "\n",
    "elem 1 in truple : Dict with 3 pairs key-value: input_ids, attention mask, token_type_ids   \n",
    "elem 2 in truple: labels's ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GvlwvPANJucM"
   },
   "outputs": [],
   "source": [
    "# Data_token=DataSequence(df_train[43:100],labels_to_ids,label_all_tokens)\n",
    "# Data_token.__getitem__(20)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdh9J3ilJucM"
   },
   "source": [
    "### Torch's model definition\n",
    "Define a model class in torch's way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "t1maOjmkJucM"
   },
   "outputs": [],
   "source": [
    "class BertModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(BertModel, self).__init__()   #for pytorch, this lign is obligatory\n",
    "\n",
    "        self.bert = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=len(unique_labels))  #transformer layer\n",
    "\n",
    "    def forward(self, input_id, mask, label):\n",
    "\n",
    "        output = self.bert(input_ids=input_id, attention_mask=mask, labels=label, return_dict=False)  \n",
    "                                                                                    #self.bert equal to model\n",
    "                                                                                    #return_dict=false -> return value is a tuple of (loss, logits)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jysu47ifJucM"
   },
   "source": [
    "### About the warning of BertForTokenClassifica\n",
    "You may occur such warning:   \n",
    "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification:....   \n",
    "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).   \n",
    "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).   \n",
    "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly  initialized: ['classifier.bias', 'classifier.weight']\n",
    "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.   \n",
    "\n",
    "Answer:  \n",
    "https://github.com/huggingface/transformers/issues/5421#issuecomment-652582854  \n",
    "\n",
    "@ohmeow you're loading the **bert-base-cased checkpoint** (which is a checkpoint that was trained using a similar architecture to BertForPreTraining) in a BertForSequenceClassification model.\n",
    "\n",
    "This means that:\n",
    "\n",
    "The layers that BertForPreTraining has, but BertForSequenceClassification does not have will be discarded  \n",
    "The layers that BertForSequenceClassification has but BertForPreTraining does not have will be randomly initialized.  \n",
    "This is expected, and tells you that you won't have good performance with your BertForSequenceClassification model before you   fine-tune it üôÇ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "h5LlEixbrqcC"
   },
   "outputs": [],
   "source": [
    "def acc_calculation(logits,train_label):\n",
    "    acc_batch=[]\n",
    "    nb_valid_label=0\n",
    "    logits_clean = [logits[i,(train_label[i]!=-100)&(train_label[i]!=8)] for i in range(len(train_label))]   #size_batch*len_sentence_without_-100\n",
    "    label_clean = [train_label[k,(train_label[k]!=-100)&(train_label[k]!=8)] for k in range(len(train_label))]   #size_batch     \n",
    "\n",
    "    ###calculate prediction and accuracy\n",
    "    prediction=[]\n",
    "    for i in range(len(logits_clean)):\n",
    "        if logits_clean[i].shape[0]!=0:\n",
    "            prediction.append(logits_clean[i].argmax(dim=1))\n",
    "        else:\n",
    "            prediction.append(torch.tensor([]))\n",
    "    for i in range(len(logits_clean)):\n",
    "        if prediction[i].shape[0]!=0:\n",
    "            acc_batch.append((prediction[i]==label_clean[i]).float().mean())\n",
    "            nb_valid_label+=1\n",
    "    acc=torch.tensor(acc_batch).sum()\n",
    "    return acc,nb_valid_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4EQcYsUJucN"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "t-C8MWiGJucN"
   },
   "outputs": [],
   "source": [
    "def train_loop(model, df_train, df_val,optimizer,EPOCHS,accumulation_steps,permit_decrease,Unkown_label):\n",
    "\n",
    "    #Dataloading\n",
    "    train_dataset = DataSequence(df_train,labels_to_ids,label_all_tokens) #output a tuple: (dict of input, list of label)\n",
    "    val_dataset = DataSequence(df_val,labels_to_ids,label_all_tokens)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)   #all in one batch\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=4)\n",
    "    \n",
    "    \n",
    "    #GPU / CPU\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    #device='cpu'\n",
    "    \n",
    "    #Presetiing\n",
    "    model=model.half().to(device)\n",
    "    best_val_acc=0\n",
    "    nb_decreasing_acc=0\n",
    "    \n",
    "    list_loss_train=[]\n",
    "    list_acc_val=[]\n",
    "\n",
    "    for epoch_num in range(EPOCHS):\n",
    "        total_nb_valide_example_train=0\n",
    "        total_nb_valide_example_val=0\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "        step=0\n",
    "\n",
    "        ######Training######\n",
    "        model.train()\n",
    "\n",
    "        for train_data, train_label in tqdm(train_dataloader): \n",
    "            step=step+1\n",
    "            train_label = train_label.to(device)   #get label\n",
    "            mask = train_data['attention_mask'].to(device)   #get attention mask\n",
    "            input_id = train_data['input_ids'].to(device)   \n",
    "            \n",
    "            #####Sqe useless dim\n",
    "            input_id_sqe=torch.squeeze(input_id)\n",
    "            mask_sqe=torch.squeeze(mask)\n",
    "            \n",
    "            #####Forward\n",
    "            loss, logits = model(input_id_sqe, mask_sqe, train_label)   #3 input to model(see class BertModel for details)\n",
    "                                                                #loss is obvious the loss function \n",
    "                                                                #logit is the \"raw output\" of the model(quite nornal in classification model)\n",
    "                                                                #0<logits<1, for multi-classification task, it offen pass through a softmax, \n",
    "                                                                #then we get probability of  each class\n",
    "            \n",
    "            \n",
    "            ####For calculate acc, should clean off meanless data: -100\n",
    "            acc,nb_valid_example=acc_calculation(logits,train_label)\n",
    "            total_nb_valide_example_train+=nb_valid_example\n",
    "\n",
    "            total_acc_train += acc\n",
    "            total_loss_train += loss.item()\n",
    "\n",
    "            #####With accu to save GPU\n",
    "            \n",
    "            loss = loss/accumulation_steps\n",
    "            loss.backward()\n",
    "\n",
    "            if((step+1)%accumulation_steps)==0:\n",
    "              optimizer.step()        # ÂèçÂêë‰º†Êí≠ÔºåÊõ¥Êñ∞ÁΩëÁªúÂèÇÊï∞\n",
    "              optimizer.zero_grad()   # Ê∏ÖÁ©∫Ê¢ØÂ∫¶\n",
    "        if(step==1):\n",
    "          break\n",
    "            \n",
    "\n",
    "        ########evaluation######\n",
    "\n",
    "        model.eval()\n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "\n",
    "        for val_data, val_label in tqdm(val_dataloader):\n",
    "            val_label = val_label.to(device)\n",
    "            mask = val_data['attention_mask'].to(device)\n",
    "            input_id = val_data['input_ids'].to(device)\n",
    "            \n",
    "            #####Sqe useless dim\n",
    "            input_id_sqe=torch.squeeze(input_id)\n",
    "            mask_sqe=torch.squeeze(mask)\n",
    "\n",
    "            ##Forward\n",
    "            loss, logits = model(input_id_sqe, mask_sqe, train_label)\n",
    "\n",
    "            acc,nb_valid_example=acc_calculation(logits,val_label)\n",
    "            total_nb_valide_example_val+=nb_valid_example\n",
    "\n",
    "            total_acc_val += acc\n",
    "            total_loss_val += loss.item()\n",
    "\n",
    "        #####Early stop#####\n",
    "        if best_val_acc<(total_acc_val / step):\n",
    "          best_val_acc=total_acc_val / step\n",
    "          nb_decreasing_acc=0\n",
    "        else:\n",
    "          nb_decreasing_acc+=1\n",
    "        if nb_decreasing_acc==permit_decrease:\n",
    "          print('\\n\\n Overall fitting avoiding! ')\n",
    "          break\n",
    "\n",
    "        \n",
    "        val_accuracy = total_acc_val / len(df_val)\n",
    "        val_loss = total_loss_val / len(df_val)\n",
    "\n",
    "        print(\n",
    "            f'Epochs: {epoch_num + 1} | Loss: {total_loss_train / len(df_train): .3f} | Accuracy: {total_acc_train / total_nb_valide_example_train: .3f} | Val_Loss: {total_loss_val / len(df_val): .3f} | Accuracy: {total_acc_val / total_nb_valide_example_val: .3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtUJPkukM6qF"
   },
   "source": [
    "#### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L1ViaYuIJucP",
    "outputId": "f8fe7126-5ee2-486f-fe5a-39e79b79149c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:34<00:00,  5.78it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:01<00:00, 15.18it/s]\n",
      "  0%|          | 1/200 [00:00<00:35,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Loss:  0.023 | Accuracy:  0.816 | Val_Loss:  0.274 | Accuracy:  0.807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:36<00:00,  5.49it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:01<00:00, 15.46it/s]\n",
      "  0%|          | 1/200 [00:00<00:34,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Loss:  0.022 | Accuracy:  0.820 | Val_Loss:  0.307 | Accuracy:  0.807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:36<00:00,  5.49it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:01<00:00, 15.43it/s]\n",
      "  0%|          | 1/200 [00:00<00:36,  5.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Loss:  0.023 | Accuracy:  0.809 | Val_Loss:  0.265 | Accuracy:  0.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:36<00:00,  5.50it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:01<00:00, 13.44it/s]\n",
      "  0%|          | 1/200 [00:00<00:39,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Loss:  0.020 | Accuracy:  0.835 | Val_Loss:  0.213 | Accuracy:  0.814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:36<00:00,  5.45it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:01<00:00, 15.18it/s]\n",
      "  0%|          | 1/200 [00:00<00:35,  5.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Loss:  0.019 | Accuracy:  0.848 | Val_Loss:  0.183 | Accuracy:  0.817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:36<00:00,  5.52it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:01<00:00, 15.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Overall fitting avoiding! \n"
     ]
    }
   ],
   "source": [
    "#####Model path\n",
    "if Colab:\n",
    "  model_save_name = 'Bert_chinese_formal.pt'\n",
    "  Path=F\"/content/drive/MyDrive/Colab Notebooks/Output/{model_save_name}\"\n",
    "else:\n",
    "  Path=f'./Bert_chinese.pt'\n",
    "\n",
    "####################################\n",
    "#####Setting before training######\n",
    "####################################\n",
    "Start_new_training=False\n",
    "Load_from_driver=False\n",
    "Keep_training=True\n",
    "\n",
    "#####Model loading\n",
    "if Start_new_training|Load_from_driver:\n",
    "  torch.cuda.empty_cache()\n",
    "  model=BertModel()\n",
    "\n",
    "if Load_from_driver:\n",
    "  torch.cuda.empty_cache()\n",
    "  model.load_state_dict(torch.load(Path))\n",
    "\n",
    "\n",
    "##########################################\n",
    "#################Dataloading##############\n",
    "##########################################\n",
    "df = df[0:1000]    #we pick only 1000 example\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), [int(.8 * len(df)), int(.9 * len(df))])   \n",
    "\n",
    "\n",
    "\n",
    "##############Parameter setting##########\n",
    "LEARNING_RATE = 0.5e-2   \n",
    "EPOCHS = 20\n",
    "accumulation_steps=8    #with accumutlation_step bigger than 1, we can save the usage of GPU storage\n",
    "LEARNING_RATE=LEARNING_RATE*accumulation_steps  #Lr should be increased, or else the training will be too slow\n",
    "permit_decrease=3\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
    "Unkown_label=8\n",
    "#############Start training###########\n",
    "if Keep_training:\n",
    "  train_loop(model, df_train, df_val,optimizer=optimizer,EPOCHS=EPOCHS,accumulation_steps=accumulation_steps,permit_decrease=permit_decrease,Unkown_label=Unkown_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Model sava to input \n",
    "torch.save(model.state_dict(), Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8s25EGGP4iA"
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.686\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, df_test):\n",
    "    test_dataset = DataSequence(df_test,labels_to_ids,label_all_tokens)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=4)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0.0\n",
    "    total_nb_valid_example=0\n",
    "\n",
    "    for test_data, test_label in test_dataloader:\n",
    "        test_label = test_label.to(device)\n",
    "        mask = test_data['attention_mask'].to(device)\n",
    "        input_id = test_data['input_ids'].to(device)\n",
    "        \n",
    "        input_id_sqe=torch.squeeze(input_id)\n",
    "        mask_sqe=torch.squeeze(mask)\n",
    "        \n",
    "        loss, logits = model(input_id_sqe, mask_sqe, test_label)\n",
    "        \n",
    "        acc,nb_valid_example=acc_calculation(logits,test_label)\n",
    "              \n",
    "        total_acc_test += acc\n",
    "        total_nb_valid_example+=nb_valid_example\n",
    "\n",
    "    val_accuracy = total_acc_test / total_nb_valid_example\n",
    "    print(f'Test Accuracy: {total_acc_test / len(df_test): .3f}')\n",
    "\n",
    "\n",
    "evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h2RcPF91P7FS",
    "outputId": "6ff4203e-77da-46d4-c208-85c315873add"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Âº†‰∏âÂ∑≤ÁªèÂà∞Êµ∑Âçó‰∏â‰∫ö‰∫ÜÂó∑ÔºåÊùé‰Ω≥ÊåáÂÆöÂú®‰πùÊúà‰∫îÊó•Ê≤°ÊúâÂ•ΩÊûúÊ±ÅÂêÉ\n",
      "['B_PER', 'I_PER', 'O', 'O', 'O', 'B_LOC', 'I_LOC', 'I_LOC', 'O', 'O', 'O', 'O', 'B_PER', 'I_PER', 'O', 'O', 'O', 'B_T', 'I_T', 'I_T', 'I_T', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "def align_word_ids(texts):\n",
    "  \n",
    "    tokenized_inputs = tokenizer(texts, padding='max_length', max_length=512, truncation=True)\n",
    "\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "\n",
    "    previous_word_idx = None\n",
    "    label_ids = []\n",
    "\n",
    "    for word_idx in word_ids:\n",
    "\n",
    "        if word_idx is None:\n",
    "            label_ids.append(-100)\n",
    "\n",
    "        elif word_idx != previous_word_idx:\n",
    "            try:\n",
    "                label_ids.append(1)\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        else:\n",
    "            try:\n",
    "                label_ids.append(1 if label_all_tokens else -100)\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    return label_ids\n",
    "\n",
    "\n",
    "def evaluate_one_text(model, sentence):\n",
    "\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "\n",
    "    text = tokenizer(sentence, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    mask = text['attention_mask'][0].unsqueeze(0).to(device)\n",
    "\n",
    "    input_id = text['input_ids'][0].unsqueeze(0).to(device)\n",
    "    label_ids = torch.Tensor(align_word_ids(sentence)).unsqueeze(0).to(device)\n",
    "\n",
    "    logits = model(input_id, mask, None)\n",
    "    logits_clean = logits[0][label_ids != -100]\n",
    "\n",
    "    predictions = logits_clean.argmax(dim=1).tolist()\n",
    "    prediction_label = [ids_to_labels[i] for i in predictions]\n",
    "    print(sentence)\n",
    "    print(prediction_label)\n",
    "            \n",
    "evaluate_one_text(model, 'Âº†‰∏âÂ∑≤ÁªèÂà∞Êµ∑Âçó‰∏â‰∫ö‰∫ÜÂó∑ÔºåÊùé‰Ω≥ÊåáÂÆöÂú®‰πùÊúà‰∫îÊó•Ê≤°ÊúâÂ•ΩÊûúÊ±ÅÂêÉ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÊùÄÈ©¨ÁâπÂõ¢ÈïøÔºåÊàëÂà∞Ê≤àÈò≥‰∫ÜÔºå‰Ω†Âíå‰Ω†ÂæíÂºüÂë¢\n",
      "['O', 'I_PER', 'I_PER', 'O', 'O', 'O', 'O', 'O', 'B_LOC', 'I_LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "evaluate_one_text(model, 'ÊùÄÈ©¨ÁâπÂõ¢ÈïøÔºåÊàëÂà∞Ê≤àÈò≥‰∫ÜÔºå‰Ω†Âíå‰Ω†ÂæíÂºüÂë¢')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ja67f609MuJr"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "d07b84835cd9e344cfc6b36587121331cd748b79cb07c96e023b0204f3468bf8"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0b30e1f9dd8145dc896b42cf5f6e75db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "18619a87d26f44769572d9b86fe27b2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1b34f2edb3a4b1db14f0771065d7142",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_1a59fe7300b2425e8f8022516e2596ff",
      "value": " 110k/110k [00:00&lt;00:00, 267kB/s]"
     }
    },
    "1895bcecaad248f1a3629ca628c0113d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f80873f4dc5245f1acbd5dcd06e682d2",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5e94c4476ad04f4680e1a76eaa563cca",
      "value": " 29.0/29.0 [00:00&lt;00:00, 833B/s]"
     }
    },
    "1a59fe7300b2425e8f8022516e2596ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d6de102451b4d95962167f504afcd08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "21a253b6aba54884bc6c461e2aca5638": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "26440bb6e9ec49949fb645db9ef4ea97": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62fa584e4b8f4699bea1479002ff9f81",
      "max": 624,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_701f66158a644085a7648fd5279006d2",
      "value": 624
     }
    },
    "2e8f932a01244043924c9270c7723e88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b19e14b78e844adc9068ea51cef7faf9",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_1d6de102451b4d95962167f504afcd08",
      "value": " 624/624 [00:00&lt;00:00, 24.2kB/s]"
     }
    },
    "2f738a04f2b64ad3b3769c5e2bfa6947": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec495c84fa9a45e5ac826c004d41ef81",
      "max": 268943,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0b30e1f9dd8145dc896b42cf5f6e75db",
      "value": 268943
     }
    },
    "2f85a6c8c3e94cc2ac9a7ceb2117c84e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd8efd9f3b844144b3d20bacb0ce1cee",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f6201b0f0b00482bb50c6034380e1f98",
      "value": "Downloading: 100%"
     }
    },
    "2fd2ca56be0c40c89a18406f4ddfcee0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f00e2a50058944478fda51f7fd5cfe5b",
      "max": 29,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd468a3294e94e248920887ec1fd1247",
      "value": 29
     }
    },
    "349e61635cc74c3880e1dcdc424fbefa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39b2ec0232cc4c8d9f94edbd6f6f5824": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e9c6c4b3f5849069716235ad5a59a6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "554e0596bc924337beb2e7903f1932f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d5eab144ca1346fd89d614753ad8fad0",
       "IPY_MODEL_f2e1dec4abfe4076b32567bdd67ec738",
       "IPY_MODEL_18619a87d26f44769572d9b86fe27b2f"
      ],
      "layout": "IPY_MODEL_3e9c6c4b3f5849069716235ad5a59a6c"
     }
    },
    "5e94c4476ad04f4680e1a76eaa563cca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "62fa584e4b8f4699bea1479002ff9f81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "701f66158a644085a7648fd5279006d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "844fe36ff8b44ff197623646fede713f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c614b67cadb9465492de63927172911f",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b8a66518d8dc4853a607a968e51d2cea",
      "value": " 269k/269k [00:00&lt;00:00, 1.09MB/s]"
     }
    },
    "927a24da570342b093add93c64406361": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0d88595282e4d3c9cbb558f39826fa1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf106b03f01f43378a87170bf130cb9b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_349e61635cc74c3880e1dcdc424fbefa",
      "value": "Downloading: 100%"
     }
    },
    "b19e14b78e844adc9068ea51cef7faf9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1b34f2edb3a4b1db14f0771065d7142": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3c99eb84abb410d9888f87631803b22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b8a66518d8dc4853a607a968e51d2cea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf106b03f01f43378a87170bf130cb9b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c093c6bfe8ab4b69afdb8e63a7a72819": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f3f82e10e0ea4231b254d68d190325f4",
       "IPY_MODEL_2f738a04f2b64ad3b3769c5e2bfa6947",
       "IPY_MODEL_844fe36ff8b44ff197623646fede713f"
      ],
      "layout": "IPY_MODEL_f0c00fa682254c1fbcb0f9db06b8d5b2"
     }
    },
    "c614b67cadb9465492de63927172911f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd468a3294e94e248920887ec1fd1247": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d5eab144ca1346fd89d614753ad8fad0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_927a24da570342b093add93c64406361",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f84a480e089d4364bc9c2860a5e76269",
      "value": "Downloading: 100%"
     }
    },
    "dd8efd9f3b844144b3d20bacb0ce1cee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e146fc0fdad84efbbb060632723d391c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec495c84fa9a45e5ac826c004d41ef81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f00e2a50058944478fda51f7fd5cfe5b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f048a8857a654458af82e4f53ada6ce5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0c00fa682254c1fbcb0f9db06b8d5b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2e1dec4abfe4076b32567bdd67ec738": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39b2ec0232cc4c8d9f94edbd6f6f5824",
      "max": 109540,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_21a253b6aba54884bc6c461e2aca5638",
      "value": 109540
     }
    },
    "f3c4a4db469d436c9ef388d018c8fd33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2f85a6c8c3e94cc2ac9a7ceb2117c84e",
       "IPY_MODEL_26440bb6e9ec49949fb645db9ef4ea97",
       "IPY_MODEL_2e8f932a01244043924c9270c7723e88"
      ],
      "layout": "IPY_MODEL_f048a8857a654458af82e4f53ada6ce5"
     }
    },
    "f3f82e10e0ea4231b254d68d190325f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb8a3663a8cc40d288ecc0352baae919",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b3c99eb84abb410d9888f87631803b22",
      "value": "Downloading: 100%"
     }
    },
    "f6201b0f0b00482bb50c6034380e1f98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f80873f4dc5245f1acbd5dcd06e682d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f816a3771dca4f4ba559ac3ad41213bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a0d88595282e4d3c9cbb558f39826fa1",
       "IPY_MODEL_2fd2ca56be0c40c89a18406f4ddfcee0",
       "IPY_MODEL_1895bcecaad248f1a3629ca628c0113d"
      ],
      "layout": "IPY_MODEL_e146fc0fdad84efbbb060632723d391c"
     }
    },
    "f84a480e089d4364bc9c2860a5e76269": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb8a3663a8cc40d288ecc0352baae919": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
